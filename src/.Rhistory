library(knitr)
library(kableExtra)
library(AER)
library(multcomp) # for glht, mcp
library(emmeans) # for emm, emmeans
library(DescTools) #for Cohen's D
library(nnet) # for multinom
library(multilevel) #Sobel test
library(bmem)
calculateBetas <- function(model){
Vcov <- vcov(model, useScale = False)
betas <- round(coefficients(model), 3)#lmer
se <- round(sqrt(diag(Vcov)), 3)
zval <- round(betas / se, 3)
pval <- round(2*pnorm(abs(zval), lower.tail = FALSE), 3)
## print everything
cbind(betas, se, zval, pval)
}
bestgraph <- function(data=NULL, xVar=NULL, yVar=NULL, groupVar=NULL, graphTitle=NULL, xlabel=NULL){
graph <- ggplot(data, aes(x=xVar, y=yVar, color=groupVar, group=groupVar)) +
geom_point() +
geom_line() +
#scale_color_manual(values= (c("#007BA7","#FDA470"))) +
labs(x = xlabel,y = graphTitle, color = "Country") +
#theme(legend.position=c(0.3, 0.2)) +
guides(colour = guide_legend(reverse=T))
graph
}
setwd("~/repos/respect_chi2021/Experimental_Analysis/")
df <- read.csv("Respect_Analysis.csv")
df <- na.omit(df)
colnames(df)
table(df$PromptType)
chisq.test(table(df$PromptType),correct=FALSE)
table(df$PromptType,df$Response_Tone)
chisq.test(table(df$PromptType,df$Response_Tone),correct=FALSE)
table(df[df$Response_Tone != 'Shame',]$PromptType)
chisq.test(table(df[df$Response_Tone != 'Shame',]$PromptType),correct=FALSE)
table(df[df$Response_Tone != 'Neither',]$PromptType)
chisq.test(table(df[df$Response_Tone != 'Neither',]$PromptType),correct=FALSE)
table(df[df$Response_Tone == 'Neither',]$PromptType)
chisq.test(table(df[df$Response_Tone == 'Neither',]$PromptType),correct=FALSE)
table(df$Response_Tone)
library(politeness)
library(spacyr)
library(spelling)
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
#df <- read.csv("updated_df.csv")
#df <- na.omit(df)
colnames(df)
pol_per<-politeness(df$parsed_text, parser = "spacy", metric="binary", drop_blank = FALSE)
pol_df<-politeness(df$ParticipantResponse, parser = "spacy", drop_blank = TRUE)
pol_df
#df <- read.csv("updated_df.csv")
#df <- na.omit(df)
colnames(df)
#Plot
politenessPlot(pol_per,
split=df_unique$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 1)
#Plot
politenessPlot(pol_per,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 1)
df$IdentityAgreement
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 1)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = .05)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.05)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.5)
#Post-hoc tests! Manually doing holm correction because it's not in the package
l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
#Post-hoc tests! Manually doing holm correction because it's not in the package
l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
#Post-hoc tests! Manually doing holm correction because it's not in the package
l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <- p.adjust(split.p, method="holm")
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.enough
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.7)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.07)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.09)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.08)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.09)
split.enough<-names(pol_df)[(corrected_ps<0.1)&(!is.na(split.p))]
split.enough
corrected_ps
pol_df
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <- p.adjust(split.p, method="holm")
split.enough<-names(pol_df)[(corrected_ps<0.1)&(!is.na(split.p))]
split.enough
split.enough<-names(pol_df)[(corrected_ps<0.3)&(!is.na(split.p))]
split.enough
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
l_polite_split
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.p
corrected_ps <- p.adjust(split.p, method="holm")
corrected_ps
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
p.adjust(split.p, method="holm")
split.enough<-names(pol_df)[(split.p<0.3)&(!is.na(split.p))]
names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <- p.adjust(split.p, method="holm")
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <- p.adjust(split.p, method="holm")
split.p
p.adjust(split.p, method="holm")
split.p
p.adjust(as.numeric(split.p), method="holm")
as.numeric(split.p)
as.numeric(p.adjust(as.numeric(split.p), method="holm"))
p.adjust(as.numeric(split.p), method="holm")
split.p
split.p <- as.numeric(split.p)
split.p
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.p <- as.numeric(split.p)
corrected_ps <-p.adjust(as.numeric(split.p), method="holm")
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <-p.adjust(as.numeric(levels(split.p))[split.p], method="holm")
p.adjust(as.numeric(levels(split.p))[split.p], method="holm")
corrected_ps <-p.adjust(split.p, method="holm")
p.adjust(split.p, method="holm")
as.numeric(as.character(corrected_ps))
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
i
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.p
corrected_ps <- p.adjust(split.p, method="holm")
p.adjust(split.p, method="holm")
corrected_ps <- p.adjust(split.p, method="holm", n=length(split.p))
length(split.p)
split.p
p.adjust(split.p, method="holm", n=length(split.p))
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.p
p.adjust(split.p, method="holm", n=length(split.p))
corrected_ps <- p.adjust(split.p, method="bonferroni", n=length(split.p))
corrected_ps
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.09)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.08)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.05)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.06)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.07)
split.p
split.enough<-names(pol_df)[(split.p<0.05)&(!is.na(split.p))]
split.enough<-names(pol_df)[(split.p<0.05)]
split.enough
#Post-hoc tests! Manually doing holm correction because it's not in the package
#l_polite_split <- split(data.frame(pol_df), df_unique$conv_type2)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
corrected_ps <- p.adjust(split.p, method="bonferroni", n=length(split.p))
split.enough<-names(pol_df)[(split.p<0.05)]
split.enough
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.07)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.95)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Different","Same"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$PromptType,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
df$PromptType
politenessPlot(pol_df,
split=df$PromptType,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$PromptType,
split_levels = c("Neutral","Respectful"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.1)
politenessPlot(pol_df,
split=df$PromptType,
split_levels = c("Neutral","Respectful"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.05)
l_polite_split <- split(data.frame(df_polite), df$IdentityAgreement)
l_polite_split <- split(data.frame(pol_df), df$IdentityAgreement)
#split.enough<-names(df_polite)
split.p<-unlist(lapply(names(df_polite), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
#split.enough<-names(df_polite)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.enough<-names(df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
l_polite_split <- split(data.frame(pol_df), df$PromptType)
#split.enough<-names(df_polite)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.enough<-names(df_polite)
split.enough<-names(pol_df)
split.enough<-as.factor(names(pol_df))
split.enough<-names(pol_df)
split.p<-unlist(lapply(names(pol_df), function(x) stats::t.test(l_polite_split[[1]][,x],
l_polite_split[[2]][,x])$p.value))
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.p
corrected_ps <- p.adjust(split.p, method="bonferroni", n=length(split.p))
split.enough<-names(pol_df)[(corrected_ps<0.05)&(!is.na(split.p))]
split.enough
corrected_ps
pol_df_experiment<-politeness(df$ParticipantResponse, parser = "spacy", drop_blank = FALSE)
df_twitter <- read.csv("updated_df.csv")
setwd("~/Downloads/")
df_experiment <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df_experiment <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df_experiment <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df_experiment <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
df
df_twitter
df_twitter <- read.csv("updated_df.csv")
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
df <- read.csv("Respect_Analysis.csv")
setwd("~/Downloads/")
#df <- read.csv("Respect_Analysis.csv")
df_twitter <- read.csv("updated_df.csv")
df_twitter <- na.omit(df_twitter)
colnames(df)
pol_df_experiment<-politeness(df_experiment$ParticipantResponse, parser = "spacy", drop_blank = FALSE)
colnames(df_twitter)
pol_df_twitter<-politeness(df_twitter$parsed_text, parser = "spacy", drop_blank = FALSE)
pol_df_experiment<-politeness(df$ParticipantResponse, parser = "spacy", drop_blank = FALSE)
politenessProjection(
pol_df_twitter,
df$IdentityAgreement,
pol_df_experiment)
politenessProjection(
pol_df_twitter,
df$IdentityAgreement,
pol_df_experiment)
politenessProjection(
pol_df_twitter,
as.numeric(df$IdentityAgreement),
pol_df_experiment)
df$a <- as.numeric(df$IdentityAgreement)
df$a
as.numeric(df$IdentityAgreement)
df$IdentityAgreement
df$a <- as.numeric(levels(df$IdentityAgreement))
levels(df$IdentityAgreement)
politenessPlot(pol_df,
split=df$PromptType,
split_levels = c("Neutral","Respectful"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.05)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.05)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.10)
politenessPlot(pol_df,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.10)
# df_btw <- df[df$conv_type2 == 'between',]
# df_btw <- df_btw[!duplicated(df_btw$parsed_text),]
# df_with <- df[df$conv_type2 == 'within',]
# df_with <- df_with[!duplicated(df_with$parsed_text),]
# df_unique <- rbind(df_btw, df_with)
analyze_df <- cbind(pol_df_experiment, df$IdentityAgreement, df$PromptType)
analyze_df
pol_df_experiment<-politeness(df$ParticipantResponse, parser = "spacy", drop_blank = TRUE)
analyze_df <- cbind(pol_df_experiment, df$IdentityAgreement, df$PromptType)
analyze_df
names(pol_df_experiment)
politenessPlot(pol_df_experiment,
split=df$IdentityAgreement,
split_levels = c("Outgroup","Ingroup"),
split_name = "Conversation Type",
top_title = "All Language Features",
middle_out = 0.10)
names(pol_df_experiment)
list(names(pol_df_experiment))
names(pol_df_experiment)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
analyze_df
m = glm(df$IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
rename(analyze_df, c("df$IdentityAgreement"="IdentityAgreement",
"df$PromptType"="PromptType"))
library(plyr)
m = glm(df$IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
names(analyze_df)
analyze_df <- rename(analyze_df, c("df$IdentityAgreement"="IdentityAgreement",
"df$PromptType"="PromptType"))
names(analyze_df)
m = glm(df$IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
analyze_df
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
analyze_df$IdentityAgreement <- as.factor(analyze_df$IdentityAgreement)
analyze_df$PromptType <- as.factor(analyze_df$PromptType)
names(analyze_df)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
library(car)
Anova(m, type=3)
m = glm(PromptType ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
names(analyze_df)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(PromptType ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(PromptType ~  Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Give.Agency + Agreement + Acknowledgement + Bare.Command + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + First.Person.Plural + First.Person.Single + Bare.Command + Gratitude + Apology, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(PromptType ~ Hedges + Positive.Emotion + Negative.Emotion + First.Person.Plural + First.Person.Single + Bare.Command + Gratitude + Apology, data=analyze_df, family=binomial)
Anova(m, type=3)
analyze_df
m = glm(PromptType ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Second.Person + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Second.Person + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(IdentityAgreement ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Second.Person + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
m = glm(PromptType ~ Hedges + Positive.Emotion + Negative.Emotion + Impersonal.Pronoun + Swearing + Negation + Filler.Pause + Informal.Title + Formal.Title + Could.You + Can.You + For.Me + For.You + Reasoning + Reassurance + Please + First.Person.Plural + First.Person.Single + Second.Person + Give.Agency + Agreement + Acknowledgement + Bare.Command + WH.Questions + YesNo.Questions + Gratitude + Apology + Truth.Intensifier + Affirmation + Adverb.Just + Conjunction.Start, data=analyze_df, family=binomial)
Anova(m, type=3)
First.P.m = glm(First.Person.Single ~ IdentityAgreement + PromptType, data=analyze_df)
Anova(First.P.m, type=3)
Second.Person.m = glm(Second.Person ~ IdentityAgreement + PromptType, data=analyze_df)
Anova(Second.Person.m, type=3)
bcm = glm(Bare.Command ~ IdentityAgreement + PromptType, data=analyze_df)
Anova(bcm, type=3)
nem = glm(Negative.Emotion ~ IdentityAgreement + PromptType, data=analyze_df)
Anova(nem, type=3)
library(lme4)
